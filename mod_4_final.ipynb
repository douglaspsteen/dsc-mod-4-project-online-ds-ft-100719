{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod 4 Project: Zillow Housing Data Time Series Modeling & Forecasting\n",
    "\n",
    "Student: Doug Steen\n",
    "\n",
    "Instructor: James Irving, PhD\n",
    "\n",
    "Cohort: ds_ft_10072019\n",
    "\n",
    "Project Review Date: ______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background & Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fictional real estate investment company has requested assistance with the following question:\n",
    "\n",
    "- What are the five best zip codes to invest in?\n",
    "\n",
    "For this study, I am using a Zillow Housing Dataset, obtained from Zillow's research page (https://www.zillow.com/research/data/). The raw dataset is located in this repository ('zillow_data.csv'). This dataset contains monthly average home values for nearly every zip code in the U.S., with most zip codes having data from 1996 - 2018.\n",
    "\n",
    "### Target Region: Tarrant County, TX\n",
    "\n",
    "The scope of this analysis is limited to the zip codes in Tarrant County, Texas which have available measurements for the full data range (1996 - 2018). Tarrant County encompasses the western portion of the Dallas-Fort Worth (DFW) Metroplex, and most notably contains the cities of Fort Worth and Arlington.\n",
    "    \n",
    "### Method\n",
    "\n",
    "Modeling and forecasting of home values using ARIMA (Auto-regressive Integrated Moving Average) time series analysis techniques.\n",
    "\n",
    "### Selection Criteria:\n",
    "\n",
    "The five 'best' zip codes for investment in Tarrant County will be selected based on the following criteria:\n",
    "    \n",
    "-3 year forecasted return on investment (ROI)\n",
    "    \n",
    "-Confidence interval of the ROI forecast\n",
    "    \n",
    "-Quality of model prediction using a train-test split of Zillow data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries / Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:35:37.848809Z",
     "start_time": "2020-01-13T18:35:36.489422Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import cohort package\n",
    "#!pip install -U fsds_100719\n",
    "from fsds_100719.imports import *\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Display all columns of large dataframes\n",
    "pd.set_option('display.max_columns',0)\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set default plot style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:35:37.908435Z",
     "start_time": "2020-01-13T18:35:37.850371Z"
    }
   },
   "outputs": [],
   "source": [
    "def melt_data(df): #formerly called it melt_data_student with REED\n",
    "   \n",
    "    melted = pd.melt(df, id_vars=['RegionID','RegionName', 'City', 'State', 'Metro', 'CountyName', \n",
    "                                  'SizeRank'], var_name='Month', value_name='MeanValue')\n",
    "    melted['Month'] = pd.to_datetime(melted['Month'], format='%Y-%m')\n",
    "    melted = melted.dropna(subset=['MeanValue'])\n",
    "    \n",
    "    return melted\n",
    "\n",
    "\n",
    "def arima_grid_search(df, zip_code, pdq_range = range(0,4), seasonal=False, train_test=True, \n",
    "                      train_end='2015-04', show_iters=False):\n",
    "\n",
    "    # Define the p, d and q parameters to take any value within the specified range\n",
    "    p = d = q = pdq_range\n",
    "    \n",
    "    # Generate all different combinations of p, q and q triplets\n",
    "    pdq = list(itertools.product(p,d,q))\n",
    "    \n",
    "    # Get only time series object for specified zip code\n",
    "    df_zip = df.loc[df['RegionName'] == zip_code]\n",
    "\n",
    "    ts_zip = df_zip.drop(['RegionID', 'RegionName', 'City', 'State', 'Metro', 'CountyName', 'SizeRank'], axis=1)\n",
    "\n",
    "    ts_zip.set_index('Month', inplace=True)\n",
    "    \n",
    "    # If arima model is being fit as part of a train-test split, define correct training interval\n",
    "    if train_test:\n",
    "            ts_zip = ts_zip[:train_end]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    if seasonal == False:\n",
    "        for i in tqdm_notebook(pdq, desc=f'{zip_code} Grid Search Progress'):\n",
    "            model = sm.tsa.SARIMAX(ts_zip, order=i,enforce_stationarity=False,\n",
    "                                         enforce_invertibility=False)\n",
    "            out = model.fit()\n",
    "            aic = out.aic\n",
    "            results.append([i, aic])\n",
    "            if show_iters == True:\n",
    "                print([i, aic])\n",
    "        results_df = pd.DataFrame(results, columns=['pdq', 'aic'])\n",
    "        min_result = results_df.loc[results_df['aic'].idxmin()]\n",
    "        return zip_code, min_result\n",
    "    else:\n",
    "        pdqs = [(x[0], x[1], x[2], 12) for x in pdq]\n",
    "        for i in tqdm_notebook(pdq, desc=f'{zip_code} Grid Search Loop Progress'):\n",
    "            for j in tqdm_notebook(pdqs, desc=f'{zip_code} Grid Search Sub-Loop Progress'):\n",
    "                model = sm.tsa.SARIMAX(ts_zip, order=i, seasonal_order=j, enforce_stationarity=False,\n",
    "                                         enforce_invertibility=False)\n",
    "                out = model.fit()\n",
    "                aic = out.aic\n",
    "                results.append([i, j, aic])\n",
    "                if show_iters == True:\n",
    "                    print([i, j, aic])\n",
    "        results_df = pd.DataFrame(results, columns=['pdq', 'pdqs', 'aic'])\n",
    "        min_result = results_df.loc[results_df['aic'].idxmin()]\n",
    "        return zip_code, min_result\n",
    "    \n",
    "\n",
    "def predict_arima(df, zip_code, train_end, test_begin, test_end, pdq, plot=False):\n",
    "    \"\"\"Fits an ARIMA model to training data and makes a prediction on testing data for a given zip code. Returns MAPE\n",
    "    and R^2 of model test predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Dataframe containing desired time series data for all zip codes\n",
    "    zip code : int\n",
    "        Desired zip code for model fit and prediction\n",
    "    train_end : str\n",
    "        Date to signify end of training (model fit) portion (Assumed that training data is at beginning of ts)\n",
    "    test_begin : str\n",
    "        Date to signify beginning of test portion (Model predictions will begin with this date to end of time series)\n",
    "    test_end : str\n",
    "        Date to signify end of test portion (Model predictions will end with this date in time series)\n",
    "    pdq : tuple\n",
    "        Tuple of the form (p, d, q) to serve as ARIMA model parameters\n",
    "    plot : bool\n",
    "        If True, returns plot of time series and model prediction with 95% conf interval\n",
    "        (Default = False)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "    from sklearn.metrics import r2_score\n",
    "    \n",
    "    # Get only time series object for specified zip code\n",
    "    df_zip = df.loc[df['RegionName'] == zip_code]\n",
    "\n",
    "    ts_zip = df_zip.drop(['RegionID', 'RegionName', 'City', 'State', 'Metro', 'CountyName', 'SizeRank'], axis=1)\n",
    "\n",
    "    ts_zip.set_index('Month', inplace=True)\n",
    "    \n",
    "    # Define train and test subsets of time series\n",
    "    ts_zip_train = ts_zip.loc[:train_end]\n",
    "    ts_zip_test = ts_zip.loc[test_begin:]\n",
    "    \n",
    "    mod = sm.tsa.SARIMAX(ts_zip_train, order=pdq, enforce_stationarity=False,\n",
    "                                 enforce_invertibility=False)\n",
    "\n",
    "    output = mod.fit()\n",
    "    \n",
    "    # Get predictions for test portion of data\n",
    "    pred_test = output.get_prediction(start=test_begin, end=test_end)\n",
    "    pred_conf = pred_test.conf_int()\n",
    "    \n",
    "    # Model prediction performance on test data\n",
    "    y_hat_test = pred_test.predicted_mean.values\n",
    "\n",
    "    y_test = ts_zip_test.values.ravel()\n",
    "    \n",
    "    # Creating train-test prediction plot with conf interval if plot is selected\n",
    "    if plot == True:\n",
    "        \n",
    "        plt.rcParams[\"figure.figsize\"] = [8,5]\n",
    "        ax = ts_zip.plot(color='black')\n",
    "        pred_test.predicted_mean.plot(ax=ax, label='Test Prediction', alpha=.9, color='red')\n",
    "        ax.fill_between(pred_conf.index,\n",
    "                pred_conf.iloc[:, 0],\n",
    "                pred_conf.iloc[:, 1], color='red', alpha=.1, label='95% Conf. Int.')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Mean Home Value ($)')\n",
    "        plt.legend(loc=2)\n",
    "        plt.title(f'Model Prediction for {zip_code}: {test_begin} - {test_end}')\n",
    "        plt.show();\n",
    "        \n",
    "    # MAPE : Mean Absolute Percentage Error\n",
    "    mape = round(np.sum(abs((np.subtract(y_test, y_hat_test) / y_test))) / len(y_test), 3)\n",
    "\n",
    "    # R^2 Score\n",
    "    r2 = round(r2_score(y_test, y_hat_test), 3)\n",
    "\n",
    "    model_val_summary = pd.DataFrame(columns = ['Zip Code', 'MAPE (%)', 'R^2'])\n",
    "\n",
    "    model_val_summary = model_val_summary.append({'Zip Code': str(zip_code), 'pdq': pdq, \n",
    "                                                  'MAPE (%)': mape*100, 'R^2': r2}, ignore_index=True)\n",
    "\n",
    "    return model_val_summary\n",
    "\n",
    "def forecast_arima(df, zip_code, forecast_begin, forecast_end, pdq, plot=False):\n",
    "    \n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "     # Get only time series object for specified zip code\n",
    "    df_zip = df.loc[df['RegionName'] == zip_code]\n",
    "\n",
    "    ts_zip = df_zip.drop(['RegionID', 'RegionName', 'City', 'State', 'Metro', 'CountyName', 'SizeRank'], axis=1)\n",
    "\n",
    "    ts_zip.set_index('Month', inplace=True)\n",
    "    \n",
    "    ts_zip.index = pd.DatetimeIndex(ts_zip.index.values,\n",
    "                               freq='MS')\n",
    "    \n",
    "    # Generate forecast arima model object\n",
    "    fc_model = sm.tsa.SARIMAX(ts_zip, order=pdq, enforce_stationarity=False,\n",
    "                                 enforce_invertibility=False)\n",
    "    \n",
    "    # Fit model\n",
    "    fc_output = fc_model.fit()\n",
    "    \n",
    "    # Obtain model forecast for desired time period, and confidence interval\n",
    "    forecast = fc_output.get_prediction(start=forecast_begin, end=forecast_end)\n",
    "    fc_conf = forecast.conf_int()\n",
    "    \n",
    "    # Creating forecast plot with conf interval if plot is selected\n",
    "    if plot == True:\n",
    "        \n",
    "        plt.rcParams[\"figure.figsize\"] = [8,5]\n",
    "        ax = ts_zip.plot(color='black')\n",
    "        forecast.predicted_mean.plot(ax=ax, label='Forecast Prediction', alpha=.9, color='green')\n",
    "        ax.fill_between(fc_conf.index,\n",
    "                fc_conf.iloc[:, 0],\n",
    "                fc_conf.iloc[:, 1], color='green', alpha=.1, label='95% Conf. Int.')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Mean Home Value ($)')\n",
    "        plt.legend(loc=2)\n",
    "        plt.title(f'Model Forecast for {zip_code}: {forecast_begin} - {forecast_end}')\n",
    "        plt.show();\n",
    "    \n",
    "    # Calculate 3 year ROI for the forecast\n",
    "    # Initial value\n",
    "    init_val = ts_zip.values[-1]\n",
    "\n",
    "    # Final forecasted value after 3 year forecast\n",
    "    f_val = forecast.predicted_mean[-1]\n",
    "\n",
    "    ROI = np.round(((f_val - init_val) / init_val)[0], 3)\n",
    "\n",
    "    # Calculate lower & upper 95% confidence ROI values\n",
    "\n",
    "    # lower bound\n",
    "    l_f_val = fc_conf['lower MeanValue'][-1]\n",
    "\n",
    "    low_ROI = np.round(((l_f_val - init_val) / init_val)[0], 3)\n",
    "\n",
    "    # upper bound\n",
    "    u_f_val = fc_conf['upper MeanValue'][-1]\n",
    "\n",
    "    high_ROI = np.round(((u_f_val - init_val) / init_val)[0], 3)\n",
    "\n",
    "    # Size of 95% CL\n",
    "\n",
    "    size_cl = np.round(high_ROI - low_ROI, 3)\n",
    "\n",
    "    ROI_summary = pd.DataFrame(columns = ['Zip Code', 'Forecast ROI (%)', 'L 95 ROI (%)', 'H 95 ROI (%)', '95 CL Size (%)'])\n",
    "\n",
    "    ROI_summary = ROI_summary.append({'Zip Code': str(zip_code), 'Forecast ROI (%)': ROI*100, 'L 95 ROI (%)': low_ROI*100, \n",
    "                                      'H 95 ROI (%)': high_ROI*100, '95 CL Size (%)': size_cl*100}, ignore_index=True)\n",
    "\n",
    "    return ROI_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain / Scrub\n",
    "-Load Zillow dataset\n",
    "\n",
    "-Reshape data from Wide Format to Long Format\n",
    "\n",
    "-Subset dataframe for zip codes in Tarrant County, TX containing data in the full range (1996-2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:35:38.263675Z",
     "start_time": "2020-01-13T18:35:37.910210Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Zillow data\n",
    "df = pd.read_csv('zillow_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:35:38.363002Z",
     "start_time": "2020-01-13T18:35:38.265259Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subset data to Tarrant County only, preview Wide Format dataframe\n",
    "df_tarrant = df.loc[df['CountyName'] == 'Tarrant']\n",
    "df_tarrant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:35:38.403869Z",
     "start_time": "2020-01-13T18:35:38.364987Z"
    }
   },
   "outputs": [],
   "source": [
    "# Melt Tarrant Co. dataframe to Long Format\n",
    "df_melted = melt_data(df_tarrant)\n",
    "df_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:35:38.408847Z",
     "start_time": "2020-01-13T18:35:38.404856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check method to later subset dataframe by zip code\n",
    "# df_melted.loc[df_melted['RegionID'] == 76001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:35:38.418818Z",
     "start_time": "2020-01-13T18:35:38.410839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for null / missing values\n",
    "# df_melted.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:35:38.428793Z",
     "start_time": "2020-01-13T18:35:38.420815Z"
    }
   },
   "outputs": [],
   "source": [
    "tarrant_zips = df_melted['RegionName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:37:45.663239Z",
     "start_time": "2020-01-13T18:35:38.431786Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_tarrant_models = []\n",
    "for zc in tqdm_notebook(tarrant_zips, desc='Total Grid Search Progress'):\n",
    "    zip_code, min_result = arima_grid_search(df = df_melted, pdq_range=range(0,7), zip_code=zc)\n",
    "    best_tarrant_models.append({f'{zip_code}': min_result})\n",
    "print(best_tarrant_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:37:45.667228Z",
     "start_time": "2020-01-13T18:35:36.508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loop to generate dataframe of all model prediction results, ranked by MAPE (%)\n",
    "\n",
    "df_all_preds = pd.DataFrame([])\n",
    "for i in range(len(best_tarrant_models)):\n",
    "    zip_i = int(list(best_tarrant_models[i].keys())[0])\n",
    "    pdq_i = list(best_tarrant_models[i].values())[0][0]\n",
    "    \n",
    "    summ_i = predict_arima(df=df_melted, zip_code=zip_i, train_end='2015-04', test_begin='2015-05', test_end='2018-04',\n",
    "                  pdq=pdq_i, plot=False)\n",
    "    \n",
    "    df_all_preds = pd.concat([df_all_preds, summ_i], axis=0)\n",
    "    df_preds_ranked = df_all_preds.sort_values('MAPE (%)')\n",
    "df_preds_ranked.set_index('Zip Code', inplace=True)\n",
    "display(df_preds_ranked)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T17:41:18.496304Z",
     "start_time": "2020-01-13T17:41:18.109358Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:37:45.668225Z",
     "start_time": "2020-01-13T18:35:36.511Z"
    }
   },
   "outputs": [],
   "source": [
    "forecast_arima(df=df_melted, zip_code=76133, forecast_begin='2018-05', forecast_end='2021-04', pdq=(0,3,3), plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:37:45.669231Z",
     "start_time": "2020-01-13T18:35:36.513Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loop to generate dataframe of all model forecast results, ranked by ROI (%)\n",
    "\n",
    "df_all_fcs = pd.DataFrame([])\n",
    "for i in range(len(best_tarrant_models)):\n",
    "    zip_i = int(list(best_tarrant_models[i].keys())[0])\n",
    "    pdq_i = list(best_tarrant_models[i].values())[0][0]\n",
    "    \n",
    "    fc_sum_i = forecast_arima(df=df_melted, zip_code=zip_i, forecast_begin='2018-05', forecast_end='2021-04', \n",
    "                              pdq=pdq_i, plot=False)\n",
    "    \n",
    "    df_all_fcs = pd.concat([df_all_fcs, fc_sum_i], axis=0)\n",
    "    df_fcs_ranked = df_all_fcs.sort_values('Forecast ROI (%)', ascending=False)\n",
    "df_fcs_ranked.set_index('Zip Code', inplace=True)\n",
    "display(df_fcs_ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:37:45.670220Z",
     "start_time": "2020-01-13T18:35:36.515Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pred_fc = df_preds_ranked.join(df_fcs_ranked, on='Zip Code')\n",
    "df_pred_fc['inv_score'] = df_pred_fc['Forecast ROI (%)'] / (df_pred_fc['MAPE (%)'] * df_pred_fc['95 CL Size (%)'])\n",
    "\n",
    "df_pred_fc.sort_values('inv_score', ascending=False, inplace=True)\n",
    "top_5_zips = df_pred_fc[:5]\n",
    "top_5_zips\n",
    "\n",
    "worst_5_zips = df_pred_fc[-5:]\n",
    "worst_5_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:37:45.671217Z",
     "start_time": "2020-01-13T18:35:36.517Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the arima prediction graphs for the top 5 zip codes\n",
    "for i, row in top_5_zips.iterrows():\n",
    "    predict_arima(df=df_melted, zip_code=int(i), train_end='2015-04', test_begin='2015-05', test_end='2018-04', \n",
    "                  pdq=row['pdq'], plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:37:45.672215Z",
     "start_time": "2020-01-13T18:35:36.518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the 3 year arima forecasts for the top 5 zip codes\n",
    "for i, row in top_5_zips.iterrows():\n",
    "    forecast_arima(df=df_melted, zip_code=int(i), forecast_begin='2018-05', forecast_end='2021-04', \n",
    "                   pdq=row['pdq'], plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:37:45.673212Z",
     "start_time": "2020-01-13T18:35:36.521Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the arima prediction graphs for the worst 5 zip codes\n",
    "for i, row in worst_5_zips.iterrows():\n",
    "    predict_arima(df=df_melted, zip_code=int(i), train_end='2015-04', test_begin='2015-05', test_end='2018-04', \n",
    "                  pdq=row['pdq'], plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:37:45.674209Z",
     "start_time": "2020-01-13T18:35:36.523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the 3 year arima forecasts for the top 5 zip codes\n",
    "for i, row in worst_5_zips.iterrows():\n",
    "    forecast_arima(df=df_melted, zip_code=int(i), forecast_begin='2018-05', forecast_end='2021-04', \n",
    "                   pdq=row['pdq'], plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
